{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findCommunities():\n",
    "    communities = []\n",
    "    with open('C:\\\\Users\\\\ar1\\\\Documents\\ML\\\\Project\\\\Crime Prediction Data(1)\\\\Crime Prediction Data\\\\communities-crime-clean.csv', 'r') as csvfile:\n",
    "        filereader = csv.reader(csvfile)\n",
    "        j = 0\n",
    "        for i in filereader:\n",
    "            if j > 0:\n",
    "                if i[1] not in communities:\n",
    "                    communities.append(i[1])\n",
    "            j+=1\n",
    "    return communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extractData(filename,communities,addstate = False,addcommunity = False):\n",
    "    features = []\n",
    "    x=[]\n",
    "    y=[]\n",
    "    highCrime=[]\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        filereader = csv.reader(csvfile)\n",
    "        j = 0\n",
    "        for i in filereader:\n",
    "            if j > 0:\n",
    "                data = i[3:len(i)-1]\n",
    "                if addstate:\n",
    "                    state = [0.0]*56\n",
    "                    state[int(i[0])-1] = 1.0\n",
    "                    data = data + state\n",
    "                    features = features + [\"state\"+str(i) for i in range(56)]\n",
    "                if addcommunity:\n",
    "                    tmp = [0.0]*len(communities)\n",
    "                    tmp[communities.index(i[1])] = 1.0\n",
    "                    data = data + tmp\n",
    "                    features = features + communities\n",
    "                vect = np.array(data)\n",
    "                #vect = np.array(i[3:len(i)-1])\n",
    "                x.append(vect.astype(np.float))\n",
    "                if float(i[-1]) > 0.1:\n",
    "                    highCrime.append(1)\n",
    "                    y.append(1)\n",
    "                else:\n",
    "                    highCrime.append(0)\n",
    "                    y.append(0)\n",
    "            else:\n",
    "                features = i[3:len(i)-1]\n",
    "            j+=1\n",
    "        y = np.array(y)\n",
    "        x = np.array(x)\n",
    "        \n",
    "        for i in highCrime:\n",
    "            print (i)\n",
    "        \n",
    "        return x,y,features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcualtePercentage(labels):\n",
    "    n = len(labels)\n",
    "    sumTrue = sum(labels)*1.0\n",
    "    sumFalse = (n - sumTrue)*1.0\n",
    "    return sumTrue/n,sumFalse/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.62719518314099343, 0.37280481685900652)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcualtePercentage(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explaination\n",
    "1a) The above code snippet is used to find if ViolentCrimesPerPop is greater than 0.1 or not. If it is greater than 0.1, then highCrime/y is appended with 1 (1 means true) and if it less than 0.1, then highCrime/y is appended with 0 ( 0 means false). The positive and negative instances are 62.71 % and 37.29% respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decisionTree():\n",
    "    return tree.DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=None, splitter='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusionMatrix(true,predicted,labels = [1,0]):\n",
    "    return confusion_matrix(true,predicted,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_confusion_matrix(actual,predicted,clabels):\n",
    "    cm= []\n",
    "    for i in clabels:\n",
    "        tmp =[0]*len(clabels)\n",
    "        \n",
    "        for j in range(len(actual)):\n",
    "            if actual[j]== i and actual[j] == predicted[j]:\n",
    "                tmp[clabels.index(i)] += 1\n",
    "            elif actual[j]== i and actual[j] != predicted[j]:\n",
    "                tmp[clabels.index(predicted[j])] += 1\n",
    "        cm.append(tmp)\n",
    "    return np.array(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_accuracy(matrix):\n",
    "    return np.trace(matrix)*1.0/np.sum(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_precision(matrix):\n",
    "    pres = []\n",
    "    x = np.sum(matrix,axis=0)\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix)):\n",
    "            if i == j:\n",
    "                pres.append(matrix[i][j]*1.0/x[i])\n",
    "    return pres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_recall(matrix):\n",
    "    rec = []\n",
    "    x = np.sum(matrix,axis=1)\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix)):\n",
    "            if i == j:\n",
    "                rec.append(matrix[i][j]*1.0/x[i])\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_fmeasure(prec,rec):\n",
    "    tmp = []\n",
    "    for i,j in zip(prec,rec):\n",
    "        tmp.append(2.0*(i*j)/(i+j))\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluation(acutal,predicted,clabels=[1,0]):\n",
    "    confmatrix = find_confusion_matrix(acutal,predicted,clabels)\n",
    "    print (\"Confusion Matrix\")\n",
    "    print (confmatrix)\n",
    "    accuracy = find_accuracy(confmatrix)\n",
    "    print (\"Accuracy\", accuracy)\n",
    "    precision = find_precision(confmatrix)\n",
    "    print (\"Precision\", precision)\n",
    "    recall = find_recall(confmatrix)\n",
    "    print (\"Recall\", recall)\n",
    "    f_score =find_fmeasure(precision,recall)\n",
    "    print (\"F_score\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_cross_validation(X, y,clf, n_folds=5):\n",
    "    cv = KFold(len(y), n_folds)\n",
    "    accuracies = []\n",
    "    for train_ind, test_ind in cv: \n",
    "        clf.fit(X[train_ind], y[train_ind])\n",
    "        predictions = clf.predict(X[test_ind])\n",
    "        evaluation(y[test_ind],predictions)\n",
    "        accuracies.append(accuracy_score(y[test_ind], predictions))\n",
    "    avg = np.mean(accuracies)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distintCommunities = findCommunities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = 'C:\\\\Users\\\\ar1\\\\Documents\\ML\\\\Project\\\\Crime Prediction Data(1)\\\\Crime Prediction Data\\\\communities-crime-clean.csv'\n",
    "X,Y,Features = extractData(filename,distintCommunities,addstate = False,addcommunity = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = decisionTree()\n",
    "dt.fit(X[:1000],Y[:1000])\n",
    "predictedY=dt.predict(X[1000:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[458,  83],\n",
       "       [187, 265]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusionMatrix(Y[1000:],predictedY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Explaination :\n",
    " The confusion Matrix for Y( i.e HighCrime ) can be found above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[458  83]\n",
      " [187 265]]\n",
      "Accuracy 0.728096676737\n",
      "Precision [0.71007751937984498, 0.7614942528735632]\n",
      "Recall [0.84658040665434375, 0.58628318584070793]\n",
      "F_score [0.77234401349072512, 0.66249999999999998]\n"
     ]
    }
   ],
   "source": [
    "evaluation(Y[1000:],predictedY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explaination: Decision Tree Classifier\n",
    "1-b-i) The Accuracy, Precision, Recall and F_score for decision tree are as follows. \n",
    "Accuracy = 72.8096676737 %\n",
    "Precision = [0.71007751937984498, 0.7614942528735632]\n",
    "Recall = [0.84658040665434375, 0.58628318584070793]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[67  7]\n",
      " [15 11]]\n",
      "Accuracy 0.78\n",
      "Precision [0.81707317073170727, 0.61111111111111116]\n",
      "Recall [0.90540540540540537, 0.42307692307692307]\n",
      "F_score [0.85897435897435892, 0.5]\n",
      "Confusion Matrix\n",
      "[[84  7]\n",
      " [ 3  6]]\n",
      "Accuracy 0.9\n",
      "Precision [0.96551724137931039, 0.46153846153846156]\n",
      "Recall [0.92307692307692313, 0.66666666666666663]\n",
      "F_score [0.94382022471910132, 0.54545454545454553]\n",
      "Confusion Matrix\n",
      "[[82  8]\n",
      " [ 4  6]]\n",
      "Accuracy 0.88\n",
      "Precision [0.95348837209302328, 0.42857142857142855]\n",
      "Recall [0.91111111111111109, 0.59999999999999998]\n",
      "F_score [0.93181818181818188, 0.5]\n",
      "Confusion Matrix\n",
      "[[71 11]\n",
      " [ 8 10]]\n",
      "Accuracy 0.81\n",
      "Precision [0.89873417721518989, 0.47619047619047616]\n",
      "Recall [0.86585365853658536, 0.55555555555555558]\n",
      "F_score [0.88198757763975155, 0.51282051282051289]\n",
      "Confusion Matrix\n",
      "[[46  6]\n",
      " [21 27]]\n",
      "Accuracy 0.73\n",
      "Precision [0.68656716417910446, 0.81818181818181823]\n",
      "Recall [0.88461538461538458, 0.5625]\n",
      "F_score [0.77310924369747902, 0.66666666666666663]\n",
      "Confusion Matrix\n",
      "[[76 11]\n",
      " [ 9  4]]\n",
      "Accuracy 0.8\n",
      "Precision [0.89411764705882357, 0.26666666666666666]\n",
      "Recall [0.87356321839080464, 0.30769230769230771]\n",
      "F_score [0.88372093023255816, 0.28571428571428575]\n",
      "Confusion Matrix\n",
      "[[47 17]\n",
      " [15 21]]\n",
      "Accuracy 0.68\n",
      "Precision [0.75806451612903225, 0.55263157894736847]\n",
      "Recall [0.734375, 0.58333333333333337]\n",
      "F_score [0.74603174603174593, 0.56756756756756765]\n",
      "Confusion Matrix\n",
      "[[47 17]\n",
      " [15 21]]\n",
      "Accuracy 0.68\n",
      "Precision [0.75806451612903225, 0.55263157894736847]\n",
      "Recall [0.734375, 0.58333333333333337]\n",
      "F_score [0.74603174603174593, 0.56756756756756765]\n",
      "Confusion Matrix\n",
      "[[33 24]\n",
      " [13 30]]\n",
      "Accuracy 0.63\n",
      "Precision [0.71739130434782605, 0.55555555555555558]\n",
      "Recall [0.57894736842105265, 0.69767441860465118]\n",
      "F_score [0.64077669902912615, 0.61855670103092775]\n",
      "Confusion Matrix\n",
      "[[35 13]\n",
      " [16 36]]\n",
      "Accuracy 0.71\n",
      "Precision [0.68627450980392157, 0.73469387755102045]\n",
      "Recall [0.72916666666666663, 0.69230769230769229]\n",
      "F_score [0.70707070707070707, 0.71287128712871284]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76000000000000001"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_cross_validation(X[:1000],Y[:1000],dt,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explaination: Cross Validation\n",
    "1-c-i) The 10 cross validation's accuracy, Precision, Recall and F_score can be found above.\n",
    "\n",
    "1-c-ii) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7280966767371602"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumCorrect =0\n",
    "for i in range(1000,len(Y)):\n",
    "    if Y[i]==predictedY[i-1000]:\n",
    "        sumCorrect += 1\n",
    "sumCorrect*1.0/len(Y[1000:])      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featureImportance = dt.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featureImp = []\n",
    "for i in range(len(Features)):\n",
    "    if featureImportance[i]>0:\n",
    "        featureImp.append((Features[i],featureImportance[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PctKids2Par', 0.32278111488525474),\n",
       " ('racePctWhite', 0.082203238294688272),\n",
       " ('PctPopUnderPov', 0.048658176745843974),\n",
       " ('PctEmplProfServ', 0.035203148969698436),\n",
       " ('agePct12t21', 0.027832380853840724),\n",
       " ('PctImmigRec10', 0.024281954949955126),\n",
       " ('MedOwnCostPctIncNoMtg', 0.023247477297892609),\n",
       " ('pctWFarmSelf', 0.022717546732230896),\n",
       " ('PctSpeakEnglOnly', 0.0206660707739965),\n",
       " ('PctWOFullPlumb', 0.019341491277634685),\n",
       " ('MedRentPctHousInc', 0.018300835127601878),\n",
       " ('PctPersOwnOccup', 0.017301228449545635),\n",
       " ('population', 0.016801033848269645),\n",
       " ('MalePctNevMarr', 0.015552055031985921),\n",
       " ('PopDens', 0.015011036729113183),\n",
       " ('AsianPerCap', 0.014848184616094962),\n",
       " ('PctPersDenseHous', 0.014335974186864425),\n",
       " ('PctWorkMom', 0.01407484166733999),\n",
       " ('PctSameCity85', 0.013732721471532105),\n",
       " ('PctImmigRec8', 0.012818159375613213),\n",
       " ('HousVacant', 0.012569018829344561),\n",
       " ('agePct16t24', 0.011800674869372554),\n",
       " ('PctHousOccup', 0.01127882934958559),\n",
       " ('racePctAsian', 0.011188410716940751),\n",
       " ('PctBornSameState', 0.010876014015671818),\n",
       " ('racePctHisp', 0.010767253875515095),\n",
       " ('PctVacantBoarded', 0.010257198709226617),\n",
       " ('blackPerCap', 0.010232361634273764),\n",
       " ('FemalePctDiv', 0.0097798306142288533),\n",
       " ('PctUnemployed', 0.0097777606584661999),\n",
       " ('PctFam2Par', 0.0091151355559916172),\n",
       " ('pctWWage', 0.008070692940200911),\n",
       " ('NumInShelters', 0.0079677758356570105),\n",
       " ('MalePctDivorce', 0.0068363516669937138),\n",
       " ('PctEmplManu', 0.0056291387734174383),\n",
       " ('pctWInvInc', 0.0053912277407973776),\n",
       " ('PctRecentImmig', 0.0053804619601339424),\n",
       " ('PctNotHSGrad', 0.0053678384664338549),\n",
       " ('PctOccupManu', 0.0053171624076617787),\n",
       " ('PctRecImmig10', 0.0052587320515336241),\n",
       " ('PctSameState85', 0.0051272637502452869),\n",
       " ('whitePerCap', 0.0050865711807988887),\n",
       " ('MedRent', 0.0050465861463051273),\n",
       " ('PctSameHouse85', 0.0049833653887247148),\n",
       " ('PersPerFam', 0.0048831083335669394),\n",
       " ('PctHousNoPhone', 0.004842988898901484),\n",
       " ('PctRecImmig8', 0.0048297813776392107),\n",
       " ('PctLargHouseOccup', 0.0042727197918710717),\n",
       " ('agePct65up', 0.0028484798612473808),\n",
       " ('PctOccupMgmtProf', 0.0028484798612473808),\n",
       " ('RentLowQ', 0.0026601134530084619)]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(featureImp, key = lambda x:x[1],reverse= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explaination : Decision Tree Classifier\n",
    "1-b-ii ) The top features for decision tree can be found above. The reason that these are the best features is because at each split point, decision tree will choose the feature which \"best\" splits the observations. What qualifies as best varies, but generally the split is done so that the subsequent nodes are more homogenous/pure with respect to the target. There are different ways of measuring homogeneity, for example Gini, Entropy, Chi-square. \n",
    "Considering the accuracy of this alogorithm, I think new features can be added/removed to increase the accuracy of the algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
